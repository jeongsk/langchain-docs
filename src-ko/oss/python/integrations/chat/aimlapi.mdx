---
title: ChatAimlapi
---

이 가이드는 AI/ML API [채팅 모델](/oss/langchain/models)을 시작하는 데 도움을 드립니다. 모든 `ChatAimlapi` 기능 및 구성에 대한 자세한 문서는 [API 레퍼런스](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html)를 참조하세요.

[AI/ML API](https://aimlapi.com/app/?utm_source=langchain&utm_medium=github&utm_campaign=integration)는 높은 가용성과 처리량을 갖춘 수백 개의 호스팅된 기반 모델에 대한 통합 액세스를 제공합니다.

## 개요

### 통합 세부 정보

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| [ChatAimlapi](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html) | [langchain-aimlapi](https://python.langchain.com/api_reference/aimlapi/index.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-aimlapi?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-aimlapi?style=flat-square&label=%20) |

### 모델 기능

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming/) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

## 설정

AI/ML API 모델에 액세스하려면 계정을 생성하고 API 키를 받은 다음 `langchain-aimlapi` 통합 패키지를 설치해야 합니다.

### 자격 증명

[aimlapi.com](https://aimlapi.com/app/?utm_source=langchain&utm_medium=github&utm_campaign=integration)으로 이동하여 가입하고 API 키를 생성하세요. 완료한 후 `AIMLAPI_API_KEY` 환경 변수를 설정하세요:

```python
import getpass
import os

if not os.getenv("AIMLAPI_API_KEY"):
    os.environ["AIMLAPI_API_KEY"] = getpass.getpass("Enter your AI/ML API key: ")
```

모델 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정하세요:

```python
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
# os.environ["LANGSMITH_TRACING"] = "true"
```

### 설치

LangChain AI/ML API 통합은 `langchain-aimlapi` 패키지에 포함되어 있습니다:

```python
%pip install -qU langchain-aimlapi
```

## 인스턴스화

이제 모델 객체를 인스턴스화하고 채팅 완성을 생성할 수 있습니다:

```python
from langchain_aimlapi import ChatAimlapi

llm = ChatAimlapi(
    model="meta-llama/Llama-3-70b-chat-hf",
    temperature=0.7,
    max_tokens=512,
    timeout=30,
    max_retries=3,
)
```

## 호출

```python
messages = [
    ("system", "You are a helpful assistant that translates English to French."),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```output
AIMessage(content="J'adore la programmation.", response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 23, 'total_tokens': 32}, 'model_name': 'meta-llama/Llama-3-70b-chat-hf'}, id='run-...')
```

```python
print(ai_msg.content)
```

```output
J'adore la programmation.
```

## 스트리밍 호출

토큰별로 응답을 스트리밍할 수도 있습니다:

```python
for chunk in llm.stream("List top 5 programming languages in 2025 with reasons."):
    print(chunk.content, end="", flush=True)
```

## API 레퍼런스

ChatAimlapi의 모든 기능 및 구성에 대한 자세한 문서는 [API 레퍼런스](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html)를 참조하세요.
