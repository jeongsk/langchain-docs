---
title: ChatDeepSeek
---

이 문서는 DeepSeek의 호스팅된 [채팅 모델](/oss/python/langchain/models) 시작하기를 도와드립니다. 모든 ChatDeepSeek 기능 및 구성에 대한 자세한 문서는 [API 레퍼런스](https://python.langchain.com/api_reference/deepseek/chat_models/langchain_deepseek.chat_models.ChatDeepSeek.html)를 참조하세요.

<Tip>
**DeepSeek의 모델은 오픈 소스이며 로컬에서([Ollama](./ollama.ipynb)에서 예를 들어) 또는 다른 추론 제공자([Fireworks](./fireworks.ipynb), [Together](./together.ipynb) 등)에서도 실행할 수 있습니다.**

</Tip>

## 개요

### 통합 세부 정보

| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/deepseek) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [ChatDeepSeek](https://python.langchain.com/api_reference/deepseek/chat_models/langchain_deepseek.chat_models.ChatDeepSeek.html) | [langchain-deepseek](https://python.langchain.com/api_reference/deepseek/) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-deepseek?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-deepseek?style=flat-square&label=%20) |

### 모델 기능

| [도구 호출](/oss/python/langchain/tools) | [구조화된 출력](/oss/python/langchain/structured-output) | JSON mode | [이미지 입력](/oss/python/langchain/messages#multimodal) | Audio input | Video input | [토큰 수준 스트리밍](/oss/python/langchain/streaming/) | Native async | [토큰 사용량](/oss/python/langchain/models#token-usage) | [Logprobs](/oss/python/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ❌ | ❌ | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ |

<Note>
**`model="deepseek-reasoner"`를 통해 지정되는 DeepSeek-R1은 도구 호출 또는 구조화된 출력을 지원하지 않습니다. 이러한 기능은 `model="deepseek-chat"`를 통해 지정되는 DeepSeek-V3에서 [지원됩니다](https://api-docs.deepseek.com/guides/function_calling).**

</Note>

## 설정

DeepSeek 모델에 액세스하려면 DeepSeek 계정을 생성하고, API 키를 받고, `langchain-deepseek` 통합 패키지를 설치해야 합니다.

### 자격 증명

[DeepSeek의 API 키 페이지](https://platform.deepseek.com/api_keys)로 이동하여 DeepSeek에 가입하고 API 키를 생성하세요. 이 작업을 완료한 후 `DEEPSEEK_API_KEY` 환경 변수를 설정하세요:

```python
import getpass
import os

if not os.getenv("DEEPSEEK_API_KEY"):
    os.environ["DEEPSEEK_API_KEY"] = getpass.getpass("Enter your DeepSeek API key: ")
```

모델 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정하세요:

```python
# os.environ["LANGSMITH_TRACING"] = "true"
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
```

### 설치

LangChain DeepSeek 통합은 `langchain-deepseek` 패키지에 있습니다:

```python
%pip install -qU langchain-deepseek
```

## 인스턴스화

이제 모델 객체를 인스턴스화하고 채팅 완성을 생성할 수 있습니다:

```python
from langchain_deepseek import ChatDeepSeek

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    # other params...
)
```

## 호출

```python
messages = [
    (
        "system",
        "You are a helpful assistant that translates English to French. Translate the user sentence.",
    ),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg.content
```

## API 레퍼런스

모든 ChatDeepSeek 기능 및 구성에 대한 자세한 문서는 [API 레퍼런스](https://python.langchain.com/api_reference/deepseek/chat_models/langchain_deepseek.chat_models.ChatDeepSeek.html)를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/deepseek.mdx)
</Callout>
