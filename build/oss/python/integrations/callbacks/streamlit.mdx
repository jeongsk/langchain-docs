---
title: Streamlit
---

> **[Streamlit](https://streamlit.io/)은 데이터 앱을 더 빠르게 구축하고 공유하는 방법입니다.**
> Streamlit은 데이터 스크립트를 몇 분 만에 공유 가능한 웹 앱으로 변환합니다. 순수한 Python으로만 작성되며, 프론트엔드 경험이 필요하지 않습니다.
> 더 많은 예제는 [streamlit.io/generative-ai](https://streamlit.io/generative-ai)를 참조하세요.

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/langchain-ai/streamlit-agent?quickstart=1)

이 가이드에서는 `StreamlitCallbackHandler`를 사용하여 에이전트의 사고 과정과 행동을 인터랙티브한 Streamlit 앱에 표시하는 방법을 보여줍니다. MRKL 에이전트를 사용하는 아래 실행 앱으로 직접 시도해 보세요:

<iframe loading="lazy" src="https://langchain-mrkl.streamlit.app/?embed=true&embed_options=light_theme"
        style={{ width: 100 + '%', border: 'none', marginBottom: 1 + 'rem', height: 600 }}
        allow="camera;clipboard-read;clipboard-write;"
></iframe>

## 설치 및 설정

```bash
pip install langchain streamlit
```

`streamlit hello`를 실행하여 샘플 앱을 로드하고 설치가 성공적으로 완료되었는지 확인할 수 있습니다. 전체 지침은 Streamlit의
[시작 가이드 문서](https://docs.streamlit.io/library/get-started)를 참조하세요.

## 사고 과정과 행동 표시

`StreamlitCallbackHandler`를 생성하려면 출력을 렌더링할 부모 컨테이너만 제공하면 됩니다.

```python
from langchain_community.callbacks.streamlit import (
    StreamlitCallbackHandler,
)
import streamlit as st

st_callback = StreamlitCallbackHandler(st.container())
```

표시 동작을 사용자 정의하기 위한 추가 키워드 인자는
[API 레퍼런스](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streamlit.streamlit_callback_handler.StreamlitCallbackHandler.html)에 설명되어 있습니다.

### 시나리오 1: 도구를 사용하는 에이전트

현재 주로 지원되는 사용 사례는 도구를 사용하는 에이전트(또는 Agent Executor)의 동작을 시각화하는 것입니다. Streamlit 앱에서 에이전트를 생성하고
`agent.run()`에 `StreamlitCallbackHandler`를 전달하기만 하면 앱에서 사고 과정과 행동을 실시간으로 시각화할 수 있습니다.

```python
import streamlit as st
from langchain import hub
from langchain.agents import AgentExecutor, create_agent, load_tools
from langchain_openai import OpenAI

llm = OpenAI(temperature=0, streaming=True)
tools = load_tools(["ddg-search"])
prompt = hub.pull("hwchase17/react")
agent = create_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

if prompt := st.chat_input():
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        st_callback = StreamlitCallbackHandler(st.container())
        response = agent_executor.invoke(
            {"input": prompt}, {"callbacks": [st_callback]}
        )
        st.write(response["output"])
```

**참고:** 위 앱 코드가 성공적으로 실행되려면 `OPENAI_API_KEY`를 설정해야 합니다.
가장 쉬운 방법은 [Streamlit secrets.toml](https://docs.streamlit.io/library/advanced-features/secrets-management)을 사용하거나
다른 로컬 환경 변수 관리 도구를 사용하는 것입니다.

### 추가 시나리오

현재 `StreamlitCallbackHandler`는 LangChain Agent Executor와 함께 사용하도록 설계되었습니다. 추가적인 에이전트 타입, 체인과의 직접 사용 등에 대한 지원은 향후 추가될 예정입니다.

---

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/callbacks/streamlit.mdx)
</Callout>
