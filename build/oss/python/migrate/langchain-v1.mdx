---
title: LangChain v1 마이그레이션 가이드
sidebarTitle: 마이그레이션 가이드
---

이 가이드는 [LangChain v1](/oss/python/releases/langchain-v1)과 이전 버전 간의 주요 변경 사항을 설명합니다.

## 간소화된 패키지

`langchain` 패키지 네임스페이스는 v1에서 에이전트의 필수 구성 요소에 집중하도록 대폭 축소되었습니다. 간소화된 패키지를 통해 핵심 기능을 더 쉽게 찾고 사용할 수 있습니다.

### 네임스페이스

| 모듈                    | 사용 가능한 항목                               | 비고                             |
|-------------------------|------------------------------------------------|-----------------------------------|
| `langchain.agents`      | `create_agent`, `AgentState`                   | 핵심 에이전트 생성 기능 |
| `langchain.messages`    | 메시지 타입, 콘텐츠 블록, `trim_messages` | `langchain-core`에서 재내보냄 |
| `langchain.tools`       | `tool`, `BaseTool`, 주입 헬퍼          | `langchain-core`에서 재내보냄 |
| `langchain.chat_models` | `init_chat_model`, `BaseChatModel`             | 통합 모델 초기화      |
| `langchain.embeddings`  | `init_embeddings`, `Embeddings`                | 임베딩 모델                  |

### `langchain-classic`

`langchain` 패키지에서 다음 중 하나를 사용하고 있었다면 [`langchain-classic`](https://pypi.org/project/langchain-classic/)을 설치하고 import를 업데이트해야 합니다:

- 레거시 체인 (`LLMChain`, `ConversationChain` 등)
- 인덱싱 API
- [`langchain-community`](https://pypi.org/project/langchain-community) 재내보내기
- 기타 더 이상 사용되지 않는 기능

<CodeGroup>
```python v1 (new)
# 레거시 체인의 경우
from langchain_classic.chains import LLMChain

# 인덱싱의 경우
from langchain_classic.indexes import ...
```

```python v0 (old)
# 체인
from langchain.chains import LLMChain

# 인덱싱
from langchain.indexes import ...
```
</CodeGroup>


다음과 같이 설치합니다:

<CodeGroup>
```bash pip
pip install langchain-classic
```

```bash uv
uv add langchain-classic
```
</CodeGroup>

---

## `create_agent`로 마이그레이션

v1.0 이전에는 에이전트를 구축하기 위해 `langgraph.prebuilt.create_react_agent`를 사용하는 것을 권장했습니다.
이제는 에이전트를 구축하기 위해 `langchain.agents.create_agent`를 사용하는 것을 권장합니다.

아래 표는 `create_react_agent`에서 `create_agent`로 변경된 기능을 요약합니다:

| 섹션 | 요약 - 변경 사항 |
|---------|--------------|
| [Import 경로](#import-path) | 패키지가 `langgraph.prebuilt`에서 `langchain.agents`로 이동 |
| [프롬프트](#prompts) | 매개변수가 `system_prompt`로 이름 변경, 동적 프롬프트는 미들웨어 사용 |
| [Pre-model 훅](#pre-model-hook) | `before_model` 메서드가 있는 미들웨어로 대체 |
| [Post-model 훅](#post-model-hook) | `after_model` 메서드가 있는 미들웨어로 대체 |
| [커스텀 상태](#custom-state) | 미들웨어에서 정의, `TypedDict`만 사용 |
| [모델](#model) | 미들웨어를 통한 동적 선택, 사전 바인딩된 모델 미지원 |
| [도구](#tools) | 도구 오류 처리가 `wrap_tool_call`이 있는 미들웨어로 이동 |
| [구조화된 출력](#structured-output) | 프롬프트 출력 제거, `ToolStrategy`/`ProviderStrategy` 사용 |
| [스트리밍 노드 이름](#streaming-node-name-rename) | 노드 이름이 `"agent"`에서 `"model"`로 변경 |
| [런타임 컨텍스트](#runtime-context) | `config["configurable"]` 대신 `context` 인수를 통한 의존성 주입 |
| [네임스페이스](#simplified-namespace) | 에이전트 구성 요소에 집중하도록 간소화, 레거시 코드는 `langchain-classic`으로 이동 |

### Import 경로

에이전트 사전 빌드의 import 경로가 `langgraph.prebuilt`에서 `langchain.agents`로 변경되었습니다.
함수 이름이 `create_react_agent`에서 `create_agent`로 변경되었습니다:

```python
from langgraph.prebuilt import create_react_agent # [!code --]
from langchain.agents import create_agent # [!code ++]
```

자세한 내용은 [에이전트](/oss/python/python/langchain/agents)를 참조하세요.

### 프롬프트

#### 정적 프롬프트 이름 변경

`prompt` 매개변수가 `system_prompt`로 이름이 변경되었습니다:

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[check_weather],
    system_prompt="You are a helpful assistant"  # [!code highlight]
)
```
```python v0 (old)
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[check_weather],
    prompt="You are a helpful assistant"  # [!code highlight]
)
```
</CodeGroup>

#### `SystemMessage`를 문자열로

시스템 프롬프트에서 `SystemMessage` 객체를 사용하는 경우, 문자열 콘텐츠를 추출합니다:

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[check_weather],
    system_prompt="You are a helpful assistant"  # [!code highlight]
)
```
```python v0 (old)
from langchain.messages import SystemMessage
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[check_weather],
    prompt=SystemMessage(content="You are a helpful assistant")  # [!code highlight]
)
```
</CodeGroup>

#### 동적 프롬프트

동적 프롬프트는 핵심 컨텍스트 엔지니어링 패턴입니다. 현재 대화 상태에 따라 모델에 전달하는 내용을 조정합니다. 이를 위해 `@dynamic_prompt` 데코레이터를 사용합니다:

<CodeGroup>
```python v1 (new)
from dataclasses import dataclass

from langchain.agents import create_agent
from langchain.agents.middleware import dynamic_prompt, ModelRequest
from langgraph.runtime import Runtime

@dataclass
class Context:  # [!code highlight]
    user_role: str = "user"

@dynamic_prompt  # [!code highlight]
def dynamic_prompt(request: ModelRequest) -> str:  # [!code highlight]
    user_role = request.runtime.context.user_role
    base_prompt = "You are a helpful assistant."

    if user_role == "expert":
        prompt = (
            f"{base_prompt} Provide detailed technical responses."
        )
    elif user_role == "beginner":
        prompt = (
            f"{base_prompt} Explain concepts simply and avoid jargon."
        )
    else:
        prompt = base_prompt

    return prompt  # [!code highlight]

agent = create_agent(
    model="openai:gpt-4o",
    tools=tools,
    middleware=[dynamic_prompt],  # [!code highlight]
    context_schema=Context
)

# Use with context
agent.invoke(
    {"messages": [{"role": "user", "content": "Explain async programming"}]},
    context=Context(user_role="expert")
)
```

```python v0 (old)
from dataclasses import dataclass

from langgraph.prebuilt import create_react_agent, AgentState
from langgraph.runtime import get_runtime

@dataclass
class Context:
    user_role: str

def dynamic_prompt(state: AgentState) -> str:
    runtime = get_runtime(Context)  # [!code highlight]
    user_role = runtime.context.user_role
    base_prompt = "You are a helpful assistant."

    if user_role == "expert":
        return f"{base_prompt} Provide detailed technical responses."
    elif user_role == "beginner":
        return f"{base_prompt} Explain concepts simply and avoid jargon."
    return base_prompt

agent = create_react_agent(
    model="openai:gpt-4o",
    tools=tools,
    prompt=dynamic_prompt,
    context_schema=Context
)

# Use with context
agent.invoke(
    {"messages": [{"role": "user", "content": "Explain async programming"}]},
    context=Context(user_role="expert")
)
```
</CodeGroup>


### Pre-model 훅

Pre-model 훅은 이제 `before_model` 메서드가 있는 미들웨어로 구현됩니다.
이 새로운 패턴은 더 확장 가능합니다. 모델이 호출되기 전에 실행할 여러 미들웨어를 정의하여
여러 에이전트에서 공통 패턴을 재사용할 수 있습니다.

일반적인 사용 사례는 다음과 같습니다:
* 대화 기록 요약
* 메시지 트리밍
* PII 편집과 같은 입력 가드레일

v1에는 이제 요약 미들웨어가 내장 옵션으로 제공됩니다:

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=tools,
    middleware=[
        SummarizationMiddleware(  # [!code highlight]
            model="anthropic:claude-sonnet-4-5-20250929",  # [!code highlight]
            max_tokens_before_summary=1000  # [!code highlight]
        )  # [!code highlight]
    ]  # [!code highlight]
)
```
```python v0 (old)
from langgraph.prebuilt import create_react_agent, AgentState

def custom_summarization_function(state: AgentState):
    """Custom logic for message summarization."""
    ...

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=tools,
    pre_model_hook=custom_summarization_function
)
```
</CodeGroup>

### Post-model 훅

Post-model 훅은 이제 `after_model` 메서드가 있는 미들웨어로 구현됩니다.
이 새로운 패턴은 더 확장 가능합니다. 모델이 호출된 후에 실행할 여러 미들웨어를 정의하여
여러 에이전트에서 공통 패턴을 재사용할 수 있습니다.

일반적인 사용 사례는 다음과 같습니다:
* [Human in the loop](/oss/python/langchain/human-in-the-loop)
* 출력 가드레일

v1에는 도구 호출에 대한 human in the loop 승인을 위한 내장 미들웨어가 있습니다:

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent
from langchain.agents.middleware import HumanInTheLoopMiddleware

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[read_email, send_email],
    middleware=[HumanInTheLoopMiddleware(
        interrupt_on={
            "send_email": True,
            "description": "Please review this email before sending"
        },
    )]
)
```

```python v0 (old)
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt import AgentState

def custom_human_in_the_loop_hook(state: AgentState):
    """Custom logic for human in the loop approval."""
    ...

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[read_email, send_email],
    post_model_hook=custom_human_in_the_loop_hook
)
```
</CodeGroup>

### 커스텀 상태

커스텀 상태는 이제 `state_schema` 속성을 사용하여 미들웨어에서 정의됩니다:

<CodeGroup>
```python v1 (new)
from typing import Annotated
from langchain.tools import tool
from langchain.agents import create_agent  # [!code highlight]
from langchain.agents.middleware import AgentMiddleware, AgentState  # [!code highlight]
from langgraph.prebuilt import InjectedState

# AgentState를 확장하는 커스텀 상태 정의
class CustomState(AgentState):
    user_name: str

# 커스텀 상태를 관리하는 미들웨어 생성
class UserStateMiddleware(AgentMiddleware[CustomState]):  # [!code highlight]
    state_schema = CustomState  # [!code highlight]

@tool  # [!code highlight]
def greet(
    state: Annotated[CustomState, InjectedState]
) -> str:
    """사용자 이름으로 인사하는 데 사용합니다."""
    user_name = state.get("user_name", "Unknown")  # [!code highlight]
    return f"Hello {user_name}!"

agent = create_agent(  # [!code highlight]
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[greet],
    middleware=[UserStateMiddleware()]  # [!code highlight]
)
```
```python v0 (old)
from typing import Annotated
from langgraph.prebuilt import InjectedState, create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

class CustomState(AgentState):
    user_name: str

def greet(
    state: Annotated[CustomState, InjectedState]
) -> str:
    """사용자 이름으로 인사하는 데 사용합니다."""
    user_name = state["user_name"]
    return f"Hello {user_name}!"

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[greet],
    state_schema=CustomState
)
```
</CodeGroup>

<Note>
    커스텀 상태는 `AgentState`를 확장하는 클래스를 생성하고 이를 미들웨어의 `state_schema` 속성에 할당하여 정의됩니다.
</Note>

#### 상태 타입 제한

`create_agent`는 이제 상태 스키마에 대해 `TypedDict`만 지원합니다. Pydantic 모델과 dataclass는 더 이상 지원되지 않습니다.

<CodeGroup>
```python v1 (new)
from langchain.agents import AgentState
from langchain.agents.middleware import AgentMiddleware

# AgentState는 TypedDict입니다
class CustomAgentState(AgentState):  # [!code highlight]
    user_id: str

class CustomAgentMiddleware(AgentMiddleware[CustomAgentState]):
    state_schema = CustomAgentState

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=tools,
    middleware=[CustomAgentMiddleware()]
)
```

```python v0 (old)
from typing_extensions import Annotated

from pydantic import BaseModel
from langgraph.graph import StateGraph
from langgraph.graph.messages import add_messages
from langchain_core.messages import AnyMessage


class AgentState(BaseModel):  # [!code highlight]
    messages: Annotated[list[AnyMessage], add_messages]
    user_id: str

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=tools,
    state_schema=AgentState
)
```
</CodeGroup>

`BaseModel`이나 `dataclass` 데코레이터 대신 `langchain.agents.AgentState`를 상속하기만 하면 됩니다.
검증이 필요한 경우, 대신 미들웨어 훅에서 처리하세요.

### 모델

동적 모델 선택을 사용하면 런타임 컨텍스트(예: 작업 복잡도, 비용 제약 또는 사용자 선호도)에 따라 다른 모델을 선택할 수 있습니다. [`langgraph-prebuilt`](https://pypi.org/project/langgraph-prebuilt) v0.6에서 릴리스된 `create_react_agent`는
`model` 매개변수에 전달된 callable을 통해 동적 모델 및 도구 선택을 지원했습니다.

이 기능은 v1에서 미들웨어 인터페이스로 포팅되었습니다.

#### 동적 모델 선택

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent
from langchain.agents.middleware import (
    AgentMiddleware, ModelRequest, ModelRequestHandler
)
from langchain.messages import AIMessage
from langchain_openai import ChatOpenAI

basic_model = ChatOpenAI(model="gpt-5-nano")
advanced_model = ChatOpenAI(model="gpt-5")

class DynamicModelMiddleware(AgentMiddleware):

    def wrap_model_call(self, request: ModelRequest, handler: ModelRequestHandler) -> AIMessage:
        if len(request.state.messages) > self.messages_threshold:
            model = advanced_model
        else:
            model = basic_model

        return handler(request.replace(model=model))

    def __init__(self, messages_threshold: int) -> None:
        self.messages_threshold = messages_threshold

agent = create_agent(
    model=basic_model,
    tools=tools,
    middleware=[DynamicModelMiddleware(messages_threshold=10)]
)
```
```python v0 (old)
from langgraph.prebuilt import create_react_agent, AgentState
from langchain_openai import ChatOpenAI

basic_model = ChatOpenAI(model="gpt-5-nano")
advanced_model = ChatOpenAI(model="gpt-5")

def select_model(state: AgentState) -> BaseChatModel:
    # use a more advanced model for longer conversations
    if len(state.messages) > 10:
        return advanced_model
    return basic_model

agent = create_react_agent(
    model=select_model,
    tools=tools,
)
```
</CodeGroup>

#### 사전 바인딩된 모델

구조화된 출력을 더 잘 지원하기 위해 `create_agent`는 더 이상 도구나 구성이 포함된 사전 바인딩된 모델을 허용하지 않습니다:

```python
# 더 이상 지원되지 않음
model_with_tools = ChatOpenAI().bind_tools([some_tool])
agent = create_agent(model_with_tools, tools=[])

# 대신 사용
agent = create_agent("openai:gpt-4o-mini", tools=[some_tool])
```

<Note>
동적 모델 함수는 구조화된 출력이 사용되지 *않는* 경우 사전 바인딩된 모델을 반환할 수 있습니다.
</Note>

### 도구

`create_agent`의 `tools` 인수는 다음 목록을 허용합니다:

* LangChain `BaseTool` 인스턴스 (`@tool`로 데코레이팅된 함수)
* 적절한 타입 힌트와 docstring이 있는 호출 가능 객체(함수)
* 내장 프로바이더 도구를 나타내는 `dict`

이 인수는 더 이상 `ToolNode` 인스턴스를 허용하지 않습니다.

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent

agent = create_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=[check_weather, search_web]
)
```
```python v0 (old)
from langgraph.prebuilt import create_react_agent, ToolNode

agent = create_react_agent(
    model="anthropic:claude-sonnet-4-5-20250929",
    tools=ToolNode([check_weather, search_web]) # [!code highlight]
)
```
</CodeGroup>

#### 도구 오류 처리

이제 `wrap_tool_call` 메서드를 구현하는 미들웨어를 사용하여 도구 오류 처리를 구성할 수 있습니다.

<CodeGroup>
```python v1 (new)
# 예제 곧 제공 예정
```
```python v0 (old)
# 예제 곧 제공 예정
```
</CodeGroup>

### 구조화된 출력

#### 노드 변경

구조화된 출력은 이전에 메인 에이전트와 별도의 노드에서 생성되었습니다. 이제는 더 이상 그렇지 않습니다.
메인 루프에서 구조화된 출력을 생성하여 비용과 지연 시간을 줄입니다.

#### 도구 및 프로바이더 전략

v1에는 두 가지 새로운 구조화된 출력 전략이 있습니다:

* `ToolStrategy`는 인위적인 도구 호출을 사용하여 구조화된 출력을 생성합니다
* `ProviderStrategy`는 프로바이더 네이티브 구조화된 출력 생성을 사용합니다

<CodeGroup>
```python v1 (new)
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy, ProviderStrategy
from pydantic import BaseModel

class OutputSchema(BaseModel):
    summary: str
    sentiment: str

# Using ToolStrategy
agent = create_agent(
    model="openai:gpt-4o-mini",
    tools=tools,
    # explicitly using tool strategy
    response_format=ToolStrategy(OutputSchema)  # [!code highlight]
)
```

```python v0 (old)
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel

class OutputSchema(BaseModel):
    summary: str
    sentiment: str

agent = create_react_agent(
    model="openai:gpt-4o-mini",
    tools=tools,
    # using tool strategy by default with no option for provider strategy
    response_format=OutputSchema  # [!code highlight]
)

# OR

agent = create_react_agent(
    model="openai:gpt-4o-mini",
    tools=tools,
    # using a custom prompt to instruct the model to generate the output schema
    response_format=("please generate ...", OutputSchema)  # [!code highlight]
)
```
</CodeGroup>

#### 프롬프트 출력 제거

**프롬프트 출력**은 더 이상 `response_format` 인수를 통해 지원되지 않습니다. 인위적인 도구 호출 및 프로바이더 네이티브 구조화된 출력과 같은 전략과 비교할 때, 프롬프트 출력은 특별히 신뢰할 만하지 않은 것으로 입증되었습니다.

### 스트리밍 노드 이름 변경

에이전트에서 이벤트를 스트리밍할 때 노드 이름이 `"agent"`에서 `"model"`로 변경되어 노드의 목적을 더 잘 반영합니다.

{/* TODO: add diagrams */}

### 런타임 컨텍스트

에이전트를 호출할 때 두 가지 유형의 데이터를 전달하려는 경우가 많습니다:
* 대화 전체에 걸쳐 변경되는 동적 상태(예: 메시지 기록)
* 대화 중에 변경되지 않는 정적 컨텍스트(예: 사용자 메타데이터)

v1에서는 `invoke` 및 `stream`에 `context` 매개변수를 설정하여 정적 컨텍스트를 지원합니다.

<CodeGroup>
```python v1 (new)
from dataclasses import dataclass

from langchain.agents import create_agent

@dataclass
class Context:
    user_id: str
    session_id: str

agent = create_agent(
    model=model,
    tools=tools,
    context_schema=ContextSchema  # [!code highlight]
)

result = agent.invoke(
    {"messages": [{"role": "user", "content": "Hello"}]},
    context=Context(user_id="123", session_id="abc")  # [!code highlight]
)
```
```python v0 (old)
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(model, tools)

# Pass context via configurable
result = agent.invoke(
    {"messages": [{"role": "user", "content": "Hello"}]},
    config={  # [!code highlight]
        "configurable": {  # [!code highlight]
            "user_id": "123",  # [!code highlight]
            "session_id": "abc"  # [!code highlight]
        }  # [!code highlight]
    }  # [!code highlight]
)
```
</CodeGroup>

<Note>
    The old `config["configurable"]` pattern still works for backward compatibility, but using the new `context` parameter is recommended for new applications or applications migrating to v1.
</Note>

---

## 표준 콘텐츠

v1에서는 메시지가 프로바이더에 구애받지 않는 표준 콘텐츠 블록을 얻습니다. `message.content_blocks`를 통해 프로바이더 전체에서 일관되고 타입이 지정된 뷰에 액세스할 수 있습니다. 기존 `message.content` 필드는 문자열 또는 프로바이더 네이티브 구조에 대해 변경되지 않습니다.

### 변경 사항

- 정규화된 콘텐츠를 위한 메시지의 새로운 `content_blocks` 속성
- [메시지](/oss/python/langchain/messages#standard-content-blocks)에 문서화된 표준화된 블록 형태
- `LC_OUTPUT_VERSION=v1` 또는 `output_version="v1"`을 통해 `content`에 표준 블록의 선택적 직렬화

### 표준화된 콘텐츠 읽기

<CodeGroup>
```python v1 (new)
from langchain.chat_models import init_chat_model

model = init_chat_model("openai:gpt-5-nano")
response = model.invoke("Explain AI")

for block in response.content_blocks:
    if block["type"] == "reasoning":
        print(block.get("reasoning"))
    elif block["type"] == "text":
        print(block.get("text"))
```
```python v0 (old)
# 프로바이더 네이티브 형식은 다양합니다. 프로바이더별 처리가 필요했습니다
response = model.invoke("Explain AI")
for item in response.content:
    if item.get("type") == "reasoning":
        ...  # OpenAI 스타일 추론
    elif item.get("type") == "thinking":
        ...  # Anthropic 스타일 사고
    elif item.get("type") == "text":
        ...  # 텍스트
```
</CodeGroup>

### 멀티모달 메시지 생성

<CodeGroup>
```python v1 (new)
from langchain.messages import HumanMessage

message = HumanMessage(content_blocks=[
    {"type": "text", "text": "Describe this image."},
    {"type": "image", "url": "https://example.com/image.jpg"},
])
res = model.invoke([message])
```
```python v0 (old)
from langchain.messages import HumanMessage

message = HumanMessage(content=[
    # 프로바이더 네이티브 구조
    {"type": "text", "text": "Describe this image."},
    {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}},
])
res = model.invoke([message])
```
</CodeGroup>

### 블록 형태 예제

```python
# 텍스트 블록
text_block = {
    "type": "text",
    "text": "Hello world",
}

# 이미지 블록
image_block = {
    "type": "image",
    "url": "https://example.com/image.png",
    "mime_type": "image/png",
}
```

자세한 내용은 콘텐츠 블록 [참조](/oss/python/langchain/messages#content-block-reference)를 참조하세요.

### 표준 콘텐츠 직렬화

표준 콘텐츠 블록은 기본적으로 `content` 속성에 **직렬화되지 않습니다**. `content` 속성의 표준 콘텐츠 블록에 액세스해야 하는 경우(예: 클라이언트에 메시지를 보낼 때), `content`에 직렬화하도록 선택할 수 있습니다.

<CodeGroup>
```bash
export LC_OUTPUT_VERSION=v1
```
```python
from langchain.chat_models import init_chat_model

model = init_chat_model(
    "openai:gpt-5-nano",
    output_version="v1",
)
```
</CodeGroup>

<Note>
    자세히 알아보기: [메시지](/oss/python/langchain/messages#content), [표준 콘텐츠 블록](/oss/python/langchain/messages#standard-content-blocks), [멀티모달](/oss/python/langchain/messages#multimodal).
</Note>

---

## 간소화된 패키지

`langchain` 패키지 네임스페이스는 v1에서 에이전트의 필수 구성 요소에 집중하도록 대폭 축소되었습니다. 간소화된 패키지를 통해 핵심 기능을 더 쉽게 찾고 사용할 수 있습니다.

### 네임스페이스

| 모듈 | 사용 가능한 항목 | 비고 |
|--------|------------------|-------|
| `langchain.agents` | `create_agent`, `AgentState` | 핵심 에이전트 생성 기능 |
| `langchain.messages` | 메시지 타입, 콘텐츠 블록, `trim_messages` | `langchain-core`에서 재내보냄 |
| `langchain.tools` | `tool`, `BaseTool`, 주입 헬퍼 | `langchain-core`에서 재내보냄 |
| `langchain.chat_models` | `init_chat_model`, `BaseChatModel` | 통합 모델 초기화 |
| `langchain.embeddings` | `Embeddings`, `init_embeddings`, | 임베딩 모델 |

### `langchain-classic`

`langchain` 패키지에서 다음 중 하나를 사용하고 있었다면 `langchain-classic`을 설치하고 import를 업데이트해야 합니다:

- 레거시 체인 (`LLMChain`, `ConversationChain` 등)
- 인덱싱 API
- `langchain-community` 재내보내기
- 기타 더 이상 사용되지 않는 기능

<CodeGroup>
```python v1 (new)
# 레거시 체인의 경우
from langchain_classic.chains import LLMChain

# 인덱싱의 경우
from langchain_classic.indexes import ...
```

```python v0 (old)
from langchain.chains import LLMChain
from langchain.indexes import ...
```
</CodeGroup>

**설치**:
```bash
uv pip install langchain-classic
```

---

## Breaking changes

### Python 3.9 지원 중단

모든 LangChain 패키지는 이제 **Python 3.10 이상**을 요구합니다. Python 3.9는 2025년 10월에 [수명 종료](https://devguide.python.org/versions/)됩니다.

### 채팅 모델의 반환 타입 업데이트

채팅 모델 호출의 반환 타입 시그니처가 `BaseMessage`에서 `AIMessage`로 수정되었습니다. `bind_tools`를 구현하는 커스텀 채팅 모델은 반환 시그니처를 업데이트해야 합니다:

<CodeGroup>
```python v1 (new)
Runnable[LanguageModelInput, AIMessage]
```
```python v0 (old)
Runnable[LanguageModelInput, BaseMessage]
```
</CodeGroup>

### OpenAI Responses API의 기본 메시지 형식

Responses API와 상호 작용할 때 `langchain-openai`는 이제 기본적으로 응답 항목을 메시지 `content`에 저장합니다. 이전 동작을 복원하려면 `LC_OUTPUT_VERSION` 환경 변수를 `v0`으로 설정하거나, `ChatOpenAI`를 인스턴스화할 때 `output_version="v0"`을 지정하세요.

```python
# output_version 플래그로 이전 동작 강제
model = ChatOpenAI(model="gpt-4o-mini", output_version="v0")
```

### `langchain-anthropic`의 기본 `max_tokens`

`max_tokens` 매개변수는 이제 이전 기본값인 `1024` 대신 선택한 모델에 따라 더 높은 값으로 기본 설정됩니다. 이전 기본값에 의존했다면 명시적으로 `max_tokens=1024`를 설정하세요.

### 레거시 코드가 `langchain-classic`으로 이동

표준 인터페이스와 에이전트의 초점을 벗어난 기존 기능은 [`langchain-classic`](https://pypi.org/project/langchain-classic) 패키지로 이동되었습니다. 핵심 `langchain` 패키지에서 사용할 수 있는 것과 `langchain-classic`으로 이동한 것에 대한 자세한 내용은 [간소화된 네임스페이스](#simplified-namespace) 섹션을 참조하세요.

### 더 이상 사용되지 않는 API 제거

이미 더 이상 사용되지 않으며 1.0에서 제거될 예정이었던 메서드, 함수 및 기타 객체가 삭제되었습니다. 대체 API는 이전 버전의 [사용 중단 공지](https://python.langchain.com/docs/versions/migrating_chains)를 확인하세요.

### `.text()`가 이제 속성임

메시지 객체의 `.text()` 메서드 사용 시 괄호를 제거해야 합니다:

<CodeGroup>
```python v1 (new)
# 속성 액세스
text = response.text

# 더 이상 사용되지 않는 메서드 호출
text = response.text()
```
```python v0 (old)
text = response.text()
```
</CodeGroup>

기존 사용 패턴(즉, `.text()`)은 계속 작동하지만 이제 경고를 표시합니다.

---

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/migrate/langchain-v1.mdx)
</Callout>
