---
title: Memory 개요
---

import AlphaCallout from '/snippets/alpha-lg-callout.mdx';

<AlphaCallout />

[Memory](/oss/javascript/langgraph/add-memory)는 이전 상호작용에 대한 정보를 기억하는 시스템입니다. AI agent에게 memory는 이전 상호작용을 기억하고, 피드백으로부터 학습하며, 사용자 선호도에 적응할 수 있게 해주기 때문에 매우 중요합니다. Agent가 수많은 사용자 상호작용과 함께 더 복잡한 작업을 수행함에 따라, 이 기능은 효율성과 사용자 만족도 모두에 필수적입니다.

이 개념 가이드는 회상 범위에 따라 두 가지 유형의 memory를 다룹니다:

* [단기 memory](#short-term-memory), 또는 [thread](/oss/javascript/langgraph/persistence#threads) 범위 memory는 세션 내에서 메시지 기록을 유지하여 진행 중인 대화를 추적합니다. LangGraph는 단기 memory를 agent의 [state](/oss/javascript/langgraph/graph-api#state)의 일부로 관리합니다. State는 [checkpointer](/oss/javascript/langgraph/persistence#checkpoints)를 사용하여 데이터베이스에 저장되므로 thread는 언제든지 재개될 수 있습니다. 단기 memory는 graph가 호출되거나 단계가 완료될 때 업데이트되며, State는 각 단계의 시작 시에 읽힙니다.
* [장기 memory](#long-term-memory)는 세션 간에 사용자별 또는 애플리케이션 수준 데이터를 저장하며 대화 thread _전체에서_ 공유됩니다. _언제든지_ 그리고 _어떤 thread에서든_ 회상될 수 있습니다. Memory는 단일 thread ID 내에서만이 아니라 모든 사용자 정의 namespace에 범위가 지정됩니다. LangGraph는 장기 memory를 저장하고 회상할 수 있도록 [store](/oss/javascript/langgraph/persistence#memory-store) ([참조 문서](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore))를 제공합니다.

![](/oss/images/short-vs-long.png)

## Short-term memory

[단기 memory](/oss/javascript/langgraph/add-memory#add-short-term-memory)는 애플리케이션이 단일 [thread](/oss/javascript/langgraph/persistence#threads) 또는 대화 내에서 이전 상호작용을 기억할 수 있게 합니다. [Thread](/oss/javascript/langgraph/persistence#threads)는 이메일이 단일 대화에서 메시지를 그룹화하는 방식과 유사하게 세션 내의 여러 상호작용을 구성합니다.

LangGraph는 단기 memory를 agent의 state의 일부로 관리하며, thread 범위 checkpoint를 통해 저장됩니다. 이 state는 일반적으로 대화 기록과 함께 업로드된 파일, 검색된 문서 또는 생성된 artifact와 같은 기타 상태 데이터를 포함할 수 있습니다. 이러한 것들을 graph의 state에 저장함으로써, bot은 서로 다른 thread 간의 분리를 유지하면서 주어진 대화에 대한 전체 컨텍스트에 액세스할 수 있습니다.

### 단기 memory 관리

대화 기록은 단기 memory의 가장 일반적인 형태이며, 긴 대화는 오늘날의 LLM에게 도전 과제입니다. 전체 기록이 LLM의 context window 안에 맞지 않을 수 있으며, 이는 복구 불가능한 오류를 초래합니다. LLM이 전체 context 길이를 지원하더라도, 대부분의 LLM은 여전히 긴 context에서 성능이 저하됩니다. 오래되거나 주제에서 벗어난 콘텐츠에 "산만해지며", 동시에 느린 응답 시간과 높은 비용을 겪습니다.

Chat model은 개발자가 제공한 지시사항(system message)과 사용자 입력(human message)을 포함하는 message를 사용하여 context를 수용합니다. Chat 애플리케이션에서 message는 사람의 입력과 model의 응답 사이에서 번갈아 나타나며, 시간이 지남에 따라 점점 길어지는 message 목록을 생성합니다. Context window가 제한되어 있고 token이 풍부한 message 목록은 비용이 많이 들 수 있기 때문에, 많은 애플리케이션은 오래된 정보를 수동으로 제거하거나 잊어버리는 기술을 사용하면 도움이 될 수 있습니다.

![](/oss/images/filter.png)

Message 관리를 위한 일반적인 기술에 대한 자세한 내용은 [Memory 추가 및 관리](/oss/javascript/langgraph/add-memory#manage-short-term-memory) 가이드를 참조하세요.

## Long-term memory

LangGraph의 [장기 memory](/oss/javascript/langgraph/add-memory#add-long-term-memory)는 시스템이 서로 다른 대화 또는 세션 간에 정보를 유지할 수 있게 합니다. **Thread 범위**로 제한된 단기 memory와 달리, 장기 memory는 사용자 정의 "namespace" 내에 저장됩니다.

장기 memory는 모든 것에 적용되는 단일 솔루션이 없는 복잡한 과제입니다. 그러나 다음 질문들은 다양한 기술을 탐색하는 데 도움이 되는 프레임워크를 제공합니다:

* [Memory의 유형은 무엇인가?](#memory-types) 인간은 사실([semantic memory](#semantic-memory)), 경험([episodic memory](#episodic-memory)), 그리고 규칙([procedural memory](#procedural-memory))을 기억하기 위해 memory를 사용합니다. AI agent도 동일한 방식으로 memory를 사용할 수 있습니다. 예를 들어, AI agent는 작업을 수행하기 위해 사용자에 대한 특정 사실을 기억하기 위해 memory를 사용할 수 있습니다.
* [언제 memory를 업데이트하고 싶은가?](#writing-memories) Memory는 agent의 애플리케이션 로직의 일부로 업데이트될 수 있습니다(예: "hot path에서"). 이 경우 agent는 일반적으로 사용자에게 응답하기 전에 사실을 기억하기로 결정합니다. 또는 memory는 백그라운드 작업(백그라운드에서 비동기적으로 실행되고 memory를 생성하는 로직)으로 업데이트될 수 있습니다. [아래 섹션](#writing-memories)에서 이러한 접근 방식 간의 장단점을 설명합니다.

### Memory 유형

서로 다른 애플리케이션은 다양한 유형의 memory를 필요로 합니다. 비유가 완벽하지는 않지만, [인간 memory 유형](https://www.psychologytoday.com/us/basics/memory/types-of-memory?ref=blog.langchain.dev)을 검토하는 것이 통찰력을 제공할 수 있습니다. 일부 연구(예: [CoALA 논문](https://arxiv.org/pdf/2309.02427))는 이러한 인간 memory 유형을 AI agent에서 사용되는 것과 매핑하기도 했습니다.

| Memory 유형 | 저장되는 것 | 인간 예시 | Agent 예시 |
|-------------|----------------|---------------|---------------|
| [Semantic](#semantic-memory) | 사실 | 학교에서 배운 것 | 사용자에 대한 사실 |
| [Episodic](#episodic-memory) | 경험 | 내가 한 일 | 과거 agent 행동 |
| [Procedural](#procedural-memory) | 지시사항 | 본능 또는 운동 기술 | Agent system prompt |

#### Semantic memory

[Semantic memory](https://en.wikipedia.org/wiki/Semantic_memory)는 인간과 AI agent 모두에서 특정 사실과 개념의 유지를 포함합니다. 인간의 경우, 학교에서 배운 정보와 개념 및 그 관계에 대한 이해를 포함할 수 있습니다. AI agent의 경우, semantic memory는 과거 상호작용에서 사실이나 개념을 기억하여 애플리케이션을 개인화하는 데 자주 사용됩니다.

<Note>
Semantic memory는 "의미"(보통 embedding으로)를 사용하여 유사한 콘텐츠를 찾는 기술인 "semantic search"와 다릅니다. Semantic memory는 사실과 지식을 저장하는 것을 의미하는 심리학 용어이며, semantic search는 정확한 일치가 아닌 의미를 기반으로 정보를 검색하는 방법입니다.
</Note>

##### Profile

Semantic memory는 다양한 방식으로 관리될 수 있습니다. 예를 들어, memory는 사용자, 조직 또는 기타 엔티티(agent 자체 포함)에 대한 범위가 잘 지정되고 구체적인 정보의 지속적으로 업데이트되는 단일 "profile"일 수 있습니다. Profile은 일반적으로 도메인을 나타내기 위해 선택한 다양한 key-value 쌍을 가진 JSON 문서입니다.

Profile을 기억할 때, 매번 profile을 **업데이트**하고 있는지 확인해야 합니다. 따라서 이전 profile을 전달하고 [model에게 새 profile을 생성하도록 요청](https://github.com/langchain-ai/memory-template)(또는 이전 profile에 적용할 [JSON patch](https://github.com/hinthornw/trustcall))해야 합니다. Profile이 커질수록 오류가 발생하기 쉬우며, profile을 여러 문서로 분할하거나 memory schema가 유효하게 유지되도록 문서를 생성할 때 **strict** 디코딩을 사용하면 도움이 될 수 있습니다.

![](/oss/images/update-profile.png)

##### Collection

또는 memory는 시간이 지남에 따라 지속적으로 업데이트되고 확장되는 문서 모음일 수 있습니다. 각 개별 memory는 범위가 더 좁고 생성하기 쉬우므로 시간이 지남에 따라 정보를 **잃을** 가능성이 적습니다. LLM이 새로운 정보를 기존 profile과 조정하는 것보다 새로운 정보에 대해 _새로운_ 객체를 생성하는 것이 더 쉽습니다. 결과적으로 문서 모음은 [더 높은 recall을 downstream으로](https://en.wikipedia.org/wiki/Precision_and_recall) 이끄는 경향이 있습니다.

그러나 이는 memory 업데이트에 일부 복잡성을 이동시킵니다. 이제 model은 목록의 기존 항목을 _삭제_하거나 _업데이트_해야 하며, 이는 까다로울 수 있습니다. 또한 일부 model은 과도하게 삽입하는 경향이 있고 다른 model은 과도하게 업데이트하는 경향이 있을 수 있습니다. 이를 관리하는 한 가지 방법으로 [Trustcall](https://github.com/hinthornw/trustcall) 패키지를 참조하고, 동작을 조정하는 데 도움이 되도록 평가(예: [LangSmith](https://docs.smith.langchain.com/tutorials/Developers/evaluation)와 같은 도구 사용)를 고려하세요.

문서 모음 작업은 또한 목록에 대한 memory **검색**으로 복잡성을 이동시킵니다. `Store`는 현재 [semantic search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.SearchOp.query)와 [콘텐츠별 필터링](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.SearchOp.filter)을 모두 지원합니다.

마지막으로, memory 모음을 사용하면 model에 포괄적인 context를 제공하기 어려울 수 있습니다. 개별 memory가 특정 schema를 따를 수 있지만, 이 구조는 memory 간의 전체 context 또는 관계를 캡처하지 못할 수 있습니다. 결과적으로 이러한 memory를 사용하여 응답을 생성할 때, model은 통합된 profile 접근 방식에서 더 쉽게 사용할 수 있는 중요한 맥락 정보가 부족할 수 있습니다.

![](/oss/images/update-list.png)

Memory 관리 접근 방식에 관계없이, 핵심은 agent가 semantic memory를 사용하여 [응답을 근거](https://python.langchain.com/docs/concepts/rag/)로 삼으며, 이는 종종 더 개인화되고 관련성 있는 상호작용으로 이어진다는 것입니다.

#### Episodic memory

[Episodic memory](https://en.wikipedia.org/wiki/Episodic_memory)는 인간과 AI agent 모두에서 과거 이벤트 또는 행동을 회상하는 것을 포함합니다. [CoALA 논문](https://arxiv.org/pdf/2309.02427)은 이를 잘 설명합니다: 사실은 semantic memory에 기록될 수 있는 반면, *경험*은 episodic memory에 기록될 수 있습니다. AI agent의 경우, episodic memory는 agent가 작업을 수행하는 방법을 기억하는 데 자주 사용됩니다.



실제로 episodic memory는 종종 few-shot example prompting을 통해 구현되며, agent는 과거 시퀀스로부터 학습하여 작업을 올바르게 수행합니다. 때로는 "말하는" 것보다 "보여주는" 것이 더 쉬우며 LLM은 예제로부터 잘 학습합니다. Few-shot learning을 사용하면 의도된 동작을 설명하기 위해 입력-출력 예제로 prompt를 업데이트하여 LLM을 ["프로그래밍"](https://x.com/karpathy/status/1627366413840322562)할 수 있습니다. Few-shot 예제를 생성하는 데 다양한 모범 사례를 사용할 수 있지만, 종종 과제는 사용자 입력을 기반으로 가장 관련성 있는 예제를 선택하는 데 있습니다.




Memory [store](/oss/javascript/langgraph/persistence#memory-store)는 few-shot 예제로 데이터를 저장하는 한 가지 방법일 뿐입니다. 더 많은 개발자 참여를 원하거나 few-shot을 평가 하네스와 더 긴밀하게 연결하려는 경우, LangSmith Dataset을 사용하여 데이터를 저장할 수도 있습니다. 그런 다음 동적 few-shot example selector를 즉시 사용하여 동일한 목표를 달성할 수 있습니다. LangSmith는 dataset을 인덱싱하고 키워드 유사성을 기반으로 사용자 입력과 가장 관련성 있는 few-shot 예제를 검색할 수 있도록 합니다.

LangSmith의 동적 few-shot example selection 사용 예제는 이 how-to [비디오](https://www.youtube.com/watch?v=37VaU7e7t5o)를 참조하세요. 또한 tool calling 성능을 개선하기 위한 few-shot prompting을 보여주는 이 [블로그 게시물](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/)과 few-shot example을 사용하여 LLM을 인간 선호도에 맞추는 이 [블로그 게시물](https://blog.langchain.dev/aligning-llm-as-a-judge-with-human-preferences/)을 참조하세요.


#### Procedural memory

[Procedural memory](https://en.wikipedia.org/wiki/Procedural_memory)는 인간과 AI agent 모두에서 작업을 수행하는 데 사용되는 규칙을 기억하는 것을 포함합니다. 인간의 경우, procedural memory는 기본 운동 기술과 균형을 통해 자전거를 타는 것과 같이 작업을 수행하는 방법에 대한 내재화된 지식과 같습니다. 반면에 episodic memory는 보조 바퀴 없이 처음으로 성공적으로 자전거를 탔던 경험이나 경치 좋은 길을 따라 기억에 남는 자전거 타기와 같은 특정 경험을 회상하는 것을 포함합니다. AI agent의 경우, procedural memory는 agent의 기능을 집합적으로 결정하는 model weight, agent 코드 및 agent의 prompt의 조합입니다.

실제로 agent가 model weight를 수정하거나 코드를 다시 작성하는 것은 상당히 드뭅니다. 그러나 agent가 자체 prompt를 수정하는 것은 더 일반적입니다.

Agent의 지시사항을 개선하는 효과적인 접근 방식 중 하나는 ["Reflection"](https://blog.langchain.dev/reflection-agents/) 또는 meta-prompting입니다. 이는 최근 대화 또는 명시적 사용자 피드백과 함께 agent에게 현재 지시사항(예: system prompt)을 제공하는 것을 포함합니다. 그런 다음 agent는 이 입력을 기반으로 자체 지시사항을 개선합니다. 이 방법은 지시사항을 미리 지정하기 어려운 작업에 특히 유용하며, agent가 상호작용으로부터 학습하고 적응할 수 있게 합니다.

예를 들어, Twitter용 고품질 논문 요약을 생성하기 위해 외부 피드백과 prompt 재작성을 사용하는 [Tweet generator](https://www.youtube.com/watch?v=Vn8A3BxfplE)를 구축했습니다. 이 경우 특정 요약 prompt는 *사전에* 지정하기 어려웠지만, 사용자가 생성된 Tweet을 비평하고 요약 프로세스를 개선하는 방법에 대한 피드백을 제공하는 것은 상당히 쉬웠습니다.

아래 의사 코드는 LangGraph memory [store](/oss/javascript/langgraph/persistence#memory-store)를 사용하여 이를 구현하는 방법을 보여줍니다. store를 사용하여 prompt를 저장하고, `update_instructions` node는 현재 prompt(및 `state["messages"]`에 캡처된 사용자와의 대화에서 피드백)를 가져오고, prompt를 업데이트하며, 새 prompt를 store에 다시 저장합니다. 그런 다음 `call_model`은 store에서 업데이트된 prompt를 가져와 응답을 생성하는 데 사용합니다.



```typescript
// Node that *uses* the instructions
const callModel = async (state: State, store: BaseStore) => {
    const namespace = ["agent_instructions"];
    const instructions = await store.get(namespace, "agent_a");
    // Application logic
    const prompt = promptTemplate.format({
        instructions: instructions[0].value.instructions
    });
    // ...
};

// Node that updates instructions
const updateInstructions = async (state: State, store: BaseStore) => {
    const namespace = ["instructions"];
    const currentInstructions = await store.search(namespace);
    // Memory logic
    const prompt = promptTemplate.format({
        instructions: currentInstructions[0].value.instructions,
        conversation: state.messages
    });
    const output = await llm.invoke(prompt);
    const newInstructions = output.new_instructions;
    await store.put(["agent_instructions"], "agent_a", {
        instructions: newInstructions
    });
    // ...
};
```


![](/oss/images/update-instructions.png)

### Memory 쓰기

Agent가 memory를 쓰는 두 가지 주요 방법이 있습니다: ["hot path에서"](#in-the-hot-path)와 ["백그라운드에서"](#in-the-background)입니다.

![](/oss/images/hot_path_vs_background.png)

#### Hot path에서

런타임 중에 memory를 생성하는 것은 장점과 과제를 모두 제공합니다. 긍정적인 측면에서, 이 접근 방식은 실시간 업데이트를 허용하여 후속 상호작용에서 새 memory를 즉시 사용할 수 있게 합니다. 또한 memory가 생성되고 저장될 때 사용자에게 알릴 수 있으므로 투명성을 가능하게 합니다.

그러나 이 방법은 과제도 제시합니다. Agent가 memory에 커밋할 내용을 결정하기 위해 새 도구가 필요한 경우 복잡성이 증가할 수 있습니다. 또한 memory에 저장할 내용에 대해 추론하는 프로세스는 agent 지연 시간에 영향을 미칠 수 있습니다. 마지막으로, agent는 memory 생성과 기타 책임 사이에서 멀티태스킹을 해야 하므로 생성된 memory의 양과 품질에 잠재적으로 영향을 미칠 수 있습니다.

예를 들어, ChatGPT는 [save_memories](https://openai.com/index/memory-and-new-controls-for-chatgpt/) 도구를 사용하여 memory를 콘텐츠 문자열로 업서트하며, 각 사용자 메시지마다 이 도구를 사용할지 여부와 방법을 결정합니다. 참조 구현으로 [memory-agent](https://github.com/langchain-ai/memory-agent) 템플릿을 참조하세요.

#### 백그라운드에서

별도의 백그라운드 작업으로 memory를 생성하는 것은 여러 장점을 제공합니다. 기본 애플리케이션의 지연 시간을 제거하고, 애플리케이션 로직을 memory 관리와 분리하며, agent가 더 집중된 작업 완료를 할 수 있도록 합니다. 이 접근 방식은 또한 중복 작업을 피하기 위해 memory 생성 시기를 조정하는 유연성을 제공합니다.

그러나 이 방법에는 고유한 과제가 있습니다. Memory 쓰기 빈도를 결정하는 것이 중요해지는데, 업데이트가 드물면 다른 thread에 새 context가 없을 수 있습니다. Memory 형성을 트리거할 시기를 결정하는 것도 중요합니다. 일반적인 전략에는 설정된 시간 후에 스케줄링(새 이벤트가 발생하면 재스케줄링), cron 스케줄 사용 또는 사용자나 애플리케이션 로직에 의한 수동 트리거 허용이 포함됩니다.

참조 구현으로 [memory-service](https://github.com/langchain-ai/memory-template) 템플릿을 참조하세요.

### Memory 저장소

LangGraph는 장기 memory를 [store](/oss/javascript/langgraph/persistence#memory-store)에 JSON 문서로 저장합니다. 각 memory는 사용자 정의 `namespace`(폴더와 유사) 및 고유한 `key`(파일 이름과 같음) 아래에 구성됩니다. Namespace에는 종종 정보를 더 쉽게 구성할 수 있도록 하는 사용자 또는 조직 ID 또는 기타 레이블이 포함됩니다. 이 구조는 memory의 계층적 구성을 가능하게 합니다. 그런 다음 콘텐츠 필터를 통해 교차 namespace 검색이 지원됩니다.



```typescript
import { InMemoryStore } from "@langchain/langgraph";

const embed = (texts: string[]): number[][] => {
    // Replace with an actual embedding function or LangChain embeddings object
    return texts.map(() => [1.0, 2.0]);
};

// InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.
const store = new InMemoryStore({ index: { embed, dims: 2 } });
const userId = "my-user";
const applicationContext = "chitchat";
const namespace = [userId, applicationContext];

await store.put(
    namespace,
    "a-memory",
    {
        rules: [
            "User likes short, direct language",
            "User only speaks English & TypeScript",
        ],
        "my-key": "my-value",
    }
);

// get the "memory" by ID
const item = await store.get(namespace, "a-memory");

// search for "memories" within this namespace, filtering on content equivalence, sorted by vector similarity
const items = await store.search(
    namespace,
    {
        filter: { "my-key": "my-value" },
        query: "language preferences"
    }
);
```


Memory store에 대한 자세한 내용은 [Persistence](/oss/javascript/langgraph/persistence#memory-store) 가이드를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/memory.mdx)
</Callout>
