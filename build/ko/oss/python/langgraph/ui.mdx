---
title: Agent Chat UI
---

import AlphaCallout from '/snippets/alpha-lg-callout.mdx';
import chat_ui from '/snippets/oss/ui.mdx';

<AlphaCallout />

<chat_ui />

### 에이전트에 연결하기

Agent Chat UI는 [로컬](/oss/python/langgraph/studio#setup-local-langgraph-server) 및 [배포된 에이전트](/oss/python/langgraph/deploy) 모두에 연결할 수 있습니다.

Agent Chat UI를 시작한 후 에이전트에 연결하도록 구성해야 합니다:

1. **Graph ID**: 그래프 이름을 입력합니다 (`langgraph.json` 파일의 `graphs` 아래에서 확인할 수 있습니다)
2. **Deployment URL**: LangGraph 서버의 엔드포인트를 입력합니다 (로컬 개발의 경우 `http://localhost:2024`, 또는 배포된 에이전트의 URL)
3. **LangSmith API key (선택사항)**: LangSmith API 키를 추가합니다 (로컬 LangGraph 서버를 사용하는 경우 필수 아님)

구성이 완료되면 Agent Chat UI가 에이전트에서 중단된 스레드를 자동으로 가져와 표시합니다.

<Tip>
  Agent Chat UI는 도구 호출 및 도구 결과 메시지 렌더링을 기본적으로 지원합니다. 표시되는 메시지를 사용자 정의하려면 [채팅에서 메시지 숨기기](https://github.com/langchain-ai/agent-chat-ui?tab=readme-ov-file#hiding-messages-in-the-chat)를 참조하세요.
</Tip>

---

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/ko/oss/python/langgraph/ui.mdx)
</Callout>
